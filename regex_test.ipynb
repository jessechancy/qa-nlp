{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit612e8b59140b4447942b36a5a3393415",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex Test\n",
    "\n",
    "Testing possible method of evaluating sentences for answers using Python Regexs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the pos_tagger for what additional modules need to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "#from nltk import parse.stanford\n",
    "from nltk import parse #need \"requests\" installed for using corenlp parse tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Potential work with query reformulation\n",
    "#See if this is more useful with that\n",
    "query1 = \"What is Gyrados most similar in appearance to?\"\n",
    "query2 = \"Where is Gyrados first seen?\" #This requires noting \"appeared\" and \"seen\" would be synonyms\n",
    "query3 = \"Where is a red Gyarados found in Pokémon Gold?\"\n",
    "query4 = \"What franchise is Gyarados in?\" #Note: the word \"franchise\" is lost in the regex, but would still be used in the query\n",
    "query5 = \"Who is Gyarados voiced by?\"\n",
    "query6 = \"What is Gyarados known as?\"\n",
    "query7 = \"How is the growth of Gyarados from Pokémon Diamond and Pearl to Pokémon Black and White described by IGN?\"\n",
    "#Note: Question could not start with wh-question word - eg. \"Gyarados is voiced by who?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[['Gyrados most similar in appearance to'], ['Gyrados first seen'], ['a red Gyarados found in Pokémon Gold'], ['Gyarados in'], ['Gyarados voiced by'], ['Gyarados known as'], ['the growth of Gyarados from Pokémon Diamond and Pearl to Pokémon Black and White described by IGN']]\n"
    }
   ],
   "source": [
    "p = re.compile('(Where |What |Who |How |Why |When )[\\w|\\s]*(is )([\\w*|\\s*]*)([?])')\n",
    "queries = [query1, query2, query3, query4, query5, query6, query7]\n",
    "\n",
    "listGroups = []\n",
    "for q in queries:\n",
    "    result = p.match(q)\n",
    "    if result == None:\n",
    "        #In actual usage, a flag would most likely be \n",
    "        #   set to indicate reformulation is not possible\n",
    "        continue\n",
    "\n",
    "    groups = result.groups()\n",
    "    listGroups.append([groups[2]])\n",
    "    #print(groups)\n",
    "    #print(groups[2])\n",
    "print(listGroups)\n",
    "#Next step is to figure out where the \"is\" should be placed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[('Gyrados', 'NNP'), ('most', 'RBS'), ('similar', 'JJ'), ('in', 'IN'), ('appearance', 'NN'), ('to', 'TO')], [('Gyrados', 'NNP'), ('first', 'RB'), ('seen', 'VBN')], [('a', 'DT'), ('red', 'JJ'), ('Gyarados', 'NNP'), ('found', 'VBD'), ('in', 'IN'), ('Pokémon', 'NNP'), ('Gold', 'NNP')], [('Gyarados', 'NNP'), ('in', 'IN')], [('Gyarados', 'NNP'), ('voiced', 'VBN'), ('by', 'IN')], [('Gyarados', 'NNP'), ('known', 'VBN'), ('as', 'IN')], [('the', 'DT'), ('growth', 'NN'), ('of', 'IN'), ('Gyarados', 'NNP'), ('from', 'IN'), ('Pokémon', 'NNP'), ('Diamond', 'NNP'), ('and', 'CC'), ('Pearl', 'NNP'), ('to', 'TO'), ('Pokémon', 'NNP'), ('Black', 'NNP'), ('and', 'CC'), ('White', 'NNP'), ('described', 'VBN'), ('by', 'IN'), ('IGN', 'NNP')]]\n"
    }
   ],
   "source": [
    "def pos_tagger(docs):\n",
    "    return nltk.pos_tag(docs)\n",
    "\n",
    "#Look at the section of the question that does not contain wh-question, \"is\", or \"?\"\n",
    "#Format for pos tagger into a list a words\n",
    "listBreakdowns = []\n",
    "for item in listGroups:\n",
    "    for section in item:\n",
    "        word_list = section.split(\" \")\n",
    "\n",
    "        #Remove excess \"\" if present in list\n",
    "        #Temporary fix\n",
    "        saved_index = -1\n",
    "        for i in range(len(word_list)):\n",
    "            if word_list[i] == \"\":\n",
    "                saved_index = i\n",
    "        \n",
    "        if saved_index != -1:\n",
    "            word_list.pop(saved_index)\n",
    "\n",
    "        #print(word_list)\n",
    "        breakdown = pos_tagger(word_list)\n",
    "        listBreakdowns.append(breakdown)\n",
    "        #print(breakdown)\n",
    "print(listBreakdowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GenericCoreNLPParser' object has no attribute 'parser_annotator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-8f08bca45a38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#parser.raw_parse('The quick brown fox jumps over the lazy dog.').pretty_print()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorenlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenericCoreNLPParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'http://localhost:9000'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The quick brown fox jumps over the lazy dog.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/nltk/parse/corenlp.py\u001b[0m in \u001b[0;36mraw_parse\u001b[0;34m(self, sentence, properties, *args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m         return next(\n\u001b[1;32m    230\u001b[0m             self.raw_parse_sents(\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_properties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m             )\n\u001b[1;32m    233\u001b[0m         )\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/nltk/parse/corenlp.py\u001b[0m in \u001b[0;36mraw_parse_sents\u001b[0;34m(self, sentences, verbose, properties, *args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mparsed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_properties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparsed_sent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentences'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/nltk/parse/corenlp.py\u001b[0m in \u001b[0;36mapi_call\u001b[0;34m(self, data, properties, timeout)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;34m'outputFormat'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             'annotators': 'tokenize,pos,lemma,ssplit,{parser_annotator}'.format(\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0mparser_annotator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser_annotator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             ),\n\u001b[1;32m    241\u001b[0m         }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GenericCoreNLPParser' object has no attribute 'parser_annotator'"
     ]
    }
   ],
   "source": [
    "#http://www.nltk.org/api/nltk.parse.html?highlight=stanford nltk.parse.stanford module\n",
    "#Use parser.tagged_parse to get tree structure of sentence form\n",
    "#   This is with the sentences tagged as above\n",
    "#   parser.parse_sents can be used on a non-tokenized sentence TODO: See if there is any\n",
    "#   performance difference between the two\n",
    "\n",
    "#parser = StanfordParser(model_path=\"edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\")\n",
    "#parser = parse.corenlp.CoreNLPParser(url='http://localhost:9000')\n",
    "#parser.raw_parse('The quick brown fox jumps over the lazy dog.').pretty_print()\n",
    "parser = parse.corenlp.GenericCoreNLPParser(url='http://localhost:9000', encoding='utf8')\n",
    "next(parser.raw_parse('The quick brown fox jumps over the lazy dog.')).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Gyrados is most similar in appearance to', 'Gyrados is first seen', 'a red Gyarados is found in Pokémon Gold', 'Gyarados is in', 'Gyarados is voiced by', 'Gyarados is known as', 'the growth of Gyarados from Pokémon Diamond and Pearl to Pokémon Black and White is described by IGN']\n"
    }
   ],
   "source": [
    "#First search for adverb, then search for verb, then propositions, \n",
    "#   place \"is\" before first one found\n",
    "#String remaining words together to form reformulated question\n",
    "listReformulation = []\n",
    "for phrase in listBreakdowns:\n",
    "    reformulation = \"\"\n",
    "    isPlaced = False\n",
    "    for tag in [\"RB\", \"VB\", \"IN\"]: #Tags checked in this order\n",
    "        reformulation = \"\"\n",
    "        for taggedWord in phrase:\n",
    "            if tag in taggedWord[1] and isPlaced == False:\n",
    "                reformulation = reformulation + \" is \" + taggedWord[0]\n",
    "                isPlaced = True\n",
    "            else:\n",
    "                if reformulation == \"\":\n",
    "                    reformulation = taggedWord[0]\n",
    "                else:\n",
    "                    reformulation = reformulation + \" \" + taggedWord[0]\n",
    "        if isPlaced == True:\n",
    "            #Only have reformulation returned if all tags have \n",
    "            #   been searched or if a tag has been found\n",
    "            break \n",
    "\n",
    "    listReformulation.append(reformulation)\n",
    "print(listReformulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Form query for each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Open Pokemon text and compare query with each sentence\n",
    "with open(\"noun_counting_data/a1.txt\") as f:\n",
    "    text = f.read()\n",
    "    paragraphs = text.split(\"\\n\")\n",
    "    sentences = []\n",
    "    for entry in paragraphs:\n",
    "        sentences.extend(entry.split(\".\"))\n",
    "print(sentences)"
   ]
  }
 ]
}
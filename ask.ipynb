{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Generation\n",
    "\n",
    "Purpose: Given an article output a list of sentences\n",
    "1. Parse Article into sentences\n",
    "2. From each sentence, generate Stanford dependency parse tree\n",
    "3. From each parse tree, use rule based method to generate question from sentence.\n",
    "4. Refine the sentences using language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article -> Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-22e07049b40b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./noun_counting_data/a1.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './noun_counting_data/a1.txt'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './noun_counting_data/a1.txt'",
     "output_type": "error"
    }
   ],
   "source": [
    "with open('./noun_counting_data/a1.txt', 'r') as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(content)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences -> Parse Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPServer\n",
    "from nltk.parse.corenlp import CoreNLPParser\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "STANFORD = os.path.join(\"models\", \"stanford-corenlp-full-2018-10-05\")\n",
    "\n",
    "# Create the server\n",
    "server = CoreNLPServer(\n",
    "   os.path.join(STANFORD, \"stanford-corenlp-3.9.2.jar\"),\n",
    "   os.path.join(STANFORD, \"stanford-corenlp-3.9.2-models.jar\"),    \n",
    ")\n",
    "server.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Stanford Parser: https://nlp.stanford.edu/software/lex-parser.shtml#Download Version 3.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tree import Tree\n",
    "parser = CoreNLPParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def list_to_string(word_list):\n",
    "    return ' '.join(word_list)\n",
    "\n",
    "def tree_to_string(parsed_tree):\n",
    "#     if isinstance(parsed_tree, str):\n",
    "#         return parsed_tree\n",
    "#     words = []\n",
    "#     for subtree in parsed_tree:\n",
    "#         words.append(tree_to_string(subtree))\n",
    "    return list_to_string(parsed_tree.leaves())\n",
    "\n",
    "def binary_question_from_tree(parsed_tree):\n",
    "    sentence = parsed_tree[0]\n",
    "    assert(sentence.label() == 'S')\n",
    "    np = sentence[0]\n",
    "    vp = sentence[1]\n",
    "    assert(np.label() == 'NP')\n",
    "    assert(vp.label() == 'VP')\n",
    "    if vp[0].label() == 'VBZ':\n",
    "        return list_to_string([vp[0][0].capitalize(), tree_to_string(np), tree_to_string(vp[1])]) + '?'\n",
    "    return vp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Sentence Structure Tree\n",
    "class SST():\n",
    "    def __init__(self, label, children):\n",
    "        self.label = label\n",
    "        self.children = children\n",
    "\n",
    "#Sentence Structure Leaf\n",
    "class SSL():\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        \n",
    "simple_predicate = SST('ROOT', [SST('S', [SSL('NP'), SSL('VP'), SSL('.')])])\n",
    "\n",
    "def satisfies_structure(parsed_tree, structure):\n",
    "    if isinstance(structure, SSL):\n",
    "        return parsed_tree.label() == structure.label\n",
    "    else:\n",
    "        if parsed_tree.label() != structure.label or len(parsed_tree) != len(structure.children): return False\n",
    "        for i in range(len(parsed_tree)):\n",
    "            if satisfies_structure(parsed_tree[i], structure.children[i]) == False:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "parse_list = []\n",
    "for sentence in sentences:\n",
    "    if len(sentence) < 180:\n",
    "        parse = next(parser.raw_parse(sentence))\n",
    "        if satisfies_structure(parse, simple_predicate):\n",
    "            print(\"=========================== Sentence ======================\")\n",
    "            print(parse)\n",
    "#             print(parse.label())\n",
    "            print(sentence) \n",
    "            print(binary_question_from_tree(parse))\n",
    "            parse_list.append(parse)\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "parse.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "server.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yes/No Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try for this test:\n",
    "\n",
    "java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\ -preload tokenize,parse,depparse,lemma \\ -status_port 9000 -port 9000 -timeout 15000 &\n",
    "\n",
    "Call for full system:\n",
    "\n",
    "java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer \\ -preload tokenize,ssplit,pos,lemma,ner,parse,depparse \\ -status_port 9000 -port 9000 -timeout 15000 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[(('used', 'VBN'), 'nsubj', ('oranges', 'NNS')),\n  (('used', 'VBN'), 'xcomp', ('considered', 'VBN')),\n  (('considered', 'VBN'), 'mark', ('to', 'TO')),\n  (('considered', 'VBN'), 'auxpass', ('be', 'VB')),\n  (('considered', 'VBN'), 'xcomp', ('poisonous', 'JJ'))]]"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "#Example Dependence Parse\n",
    "\n",
    "dep_parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "parses = dep_parser.parse('oranges used to be considered poisonous'.split())\n",
    "[[(governor, dep, dependent) for governor, dep, dependent in p.triples()] for p in parses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[[(('considered', 'VBN'), 'nsubjpass', ('organges', 'NNS')),\n  (('considered', 'VBN'), 'auxpass', ('were', 'VBD')),\n  (('considered', 'VBN'), 'xcomp', ('poisonous', 'JJ'))]]"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "parses = dep_parser.parse('organges were considered poisonous'.split())\n",
    "[[(governor, dep, dependent) for governor, dep, dependent in p.triples()] for p in parses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "rocks : rock\ncorpora : corpus\nappears : appear\n"
    }
   ],
   "source": [
    "#Lemmatizer Example\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
    "print(\"appears :\", lemmatizer.lemmatize(\"appears\", pos=\"v\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import string\n",
    "from nltk.parse import CoreNLPParser, CoreNLPDependencyParser\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Jesse's question_generation.ipynb\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def list_to_string(word_list):\n",
    "    return ' '.join(word_list)\n",
    "\n",
    "def tree_to_string(parsed_tree):\n",
    "#     if isinstance(parsed_tree, str):\n",
    "#         return parsed_tree\n",
    "#     words = []\n",
    "#     for subtree in parsed_tree:\n",
    "#         words.append(tree_to_string(subtree))\n",
    "    return list_to_string(parsed_tree.leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Structure Example\n",
    "'''\n",
    "(WHNP (WP what))\n",
    "(SQ (VBZ is) (NP (NNP Gyarados)) (VP (VBN known) (PP (IN as))))\n",
    "(. ?)\n",
    "'''\n",
    "\n",
    "#Take question tree and place verb in location after first NP with a following phrase\n",
    "#If no following phrase, place verb at end of sentence\n",
    "def recurse_make_binary_declarative(question, verb, lvl):\n",
    "    #print(\"Question:\")\n",
    "    #print(question)\n",
    "    if (lvl == 1 and len(question) >= 3) or (lvl > 1 and len(question) >= 2): #eg VBZ, NP, VP for lvl 1\n",
    "        if (lvl == 1):\n",
    "            ind = 1\n",
    "        else:\n",
    "            ind = 0\n",
    "        #print(\"IND:\")\n",
    "        #print(question[ind])\n",
    "        if question[ind].label().startswith(\"N\"):\n",
    "            n = question[ind]\n",
    "            full_list = [tree_to_string(n), verb]\n",
    "\n",
    "            remaining = []\n",
    "            for i in range(ind+1, len(question)):\n",
    "                remaining.append(tree_to_string(question[i]))\n",
    "\n",
    "            full_list.extend(remaining)\n",
    "            full = list_to_string(full_list)\n",
    "            #print(full)\n",
    "            return full\n",
    "        \n",
    "        else: #Can't handle this form if the next thing after the verb isnt a noun phrase/noun\n",
    "            print(\"ERROR: COULD NOT DETERMINE WHERE TO PLACE VERB. NO NOUN PHRASE.\")\n",
    "            return \"\"\n",
    "\n",
    "    else:\n",
    "        if (lvl == 1):\n",
    "            result = recurse_make_binary_declarative(question[1], verb, 2)\n",
    "            return result\n",
    "        elif (lvl > 1):\n",
    "            result = recurse_make_binary_declarative(question[0], verb, lvl+1)\n",
    "            return result\n",
    "        \n",
    "\n",
    "#Return string form of reformed question as a declarative statement\n",
    "def make_binary_declarative(question):\n",
    "        verb = question[0]\n",
    "        #print(\"Make Binary Declarative:\")\n",
    "        #print(\"Verb:\")\n",
    "        #print(verb[0])\n",
    "        result = recurse_make_binary_declarative(question, verb[0], 1)\n",
    "        \n",
    "        if result == \"\":\n",
    "            print(\"ERROR: COULD NOT RECONFIGURE\")\n",
    "            print(question)\n",
    "            return tree_to_string(question)\n",
    "            #FIXME: Should this be returned to signal something?\n",
    "            #return \"\" \n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Structure Example\n",
    "'''\n",
    "  (SBARQ\n",
    "    (WHNP (WP what))\n",
    "    (SQ (VBZ is) (NP (NNP Gyarados)) (VP (VBN known) (PP (IN as))))\n",
    "    (. ?))\n",
    "'''\n",
    "#Instead of making wh-questions declarative, just give Sojeong the wh question word and the sentence with it removed (can leave it in if necessary)\n",
    "\n",
    "#Return a string of the wh word from the question\n",
    "def find_wh_word(question):\n",
    "    #print(question)\n",
    "\n",
    "    if isinstance(question, str):\n",
    "        return \"\"\n",
    "\n",
    "    if question.label() in {\"WP\", \"WDT\", \"WP$\", \"WRB\"}:\n",
    "        return question[0]\n",
    "    \n",
    "    else:\n",
    "        for i in range(len(question)):\n",
    "            result = find_wh_word(question[i])\n",
    "            \n",
    "            if result != \"\":\n",
    "                return result\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "#Return strings of wh word and new sentence in the same order just without the wh word\n",
    "def get_wh_word(question):\n",
    "    \n",
    "    wh_word = find_wh_word(question)    \n",
    "    new_sentence = tree_to_string(question)\n",
    "\n",
    "    #FIXME: Can remove if this step is not necessary\n",
    "    #Remove wh word from question - FIXME: could go back and make this more efficient\n",
    "    ind_start = new_sentence.index(wh_word)\n",
    "    ind_end = ind_start + len(wh_word)\n",
    "    new_sentence = new_sentence[:ind_start] + new_sentence[ind_end:]\n",
    "    new_sentence = ' '.join(new_sentence.split())\n",
    "\n",
    "    #print(\"WH Word: \" + str(wh_word))\n",
    "    return [wh_word, new_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input Structure Example\n",
    "'''\n",
    "(ROOT\n",
    "  (SBARQ\n",
    "    (WHNP (WP what))\n",
    "    (SQ (VBZ is) (NP (NNP Gyarados)) (VP (VBN known) (PP (IN as))))\n",
    "    (. ?)))\n",
    "'''\n",
    "def make_declarative(parsed_tree):\n",
    "    \n",
    "    was_declarative = False #Mark if the sentence was already considered declarative\n",
    "    question_word = \"\"\n",
    "    #FIXME: ^Should also apply if the sentence could not be parsed\n",
    "    question = parsed_tree[0] #Indexing the ROOT\n",
    "\n",
    "    if question.label() == \"SBARQ\":\n",
    "        #Check to make sure \"SQ\" doesnt follow in case it was just misclassified\n",
    "        if question[0].label() == \"SQ\":\n",
    "            new_sentence = make_binary_declarative(question[0]) #Gets rid of random previous \"SBARQ\"\n",
    "        else:\n",
    "            [question_word, new_sentence] = get_wh_word(question)\n",
    "    elif question.label() == \"SQ\":\n",
    "        new_sentence = make_binary_declarative(question)\n",
    "\n",
    "    elif question.label() == \"S\":\n",
    "        #print(\"Already in sentence form\")\n",
    "        was_declarative = True\n",
    "        new_sentence = tree_to_string(question) #NOTE: May not want to use this new sentence as some tokens may be altered, example \"(\" and \")\" become \"-LRB-\" and \"-RRB-\" respectively\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR: Not equipt to handle questions parsed as: \" + str(question.label()))\n",
    "        was_declarative = True #NOTE: This is to flag to just do a closest match return\n",
    "        new_sentence = tree_to_string(question)\n",
    "        #new_sentence = \"\" #FIXME: Possibly include some other signal when this does not parse correctly\n",
    "        #FIXME: Recursively run through subtrees of question to find these parts?\n",
    "\n",
    "    return [question_word, was_declarative, new_sentence]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess document for queries\n",
    "sentences = []\n",
    "\n",
    "with open(\"noun_counting_data/a1.txt\") as f: #FIXME: In actual implementation, have this be a line from article.txt, argument 1 of the command line\n",
    "    text = f.read()\n",
    "    paragraphs = text.split(\"\\n\")\n",
    "    for entry in paragraphs:\n",
    "        split_entries = entry.split(\".\")\n",
    "        for se in split_entries:\n",
    "            if len(se) > 0: #Get rid of empty lines\n",
    "                sentences.append(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n(ROOT\n  (SBARQ\n    (SQ\n      (VBZ is)\n      (NP\n        (NP (DT a) (JJ red) (NN Gyarados))\n        (VP (VBN found) (PP (IN in) (NP (NNP Pokémon) (NNP Gold))))))\n    (. ?)))\n\n1\n(ROOT\n  (SBARQ\n    (SQ\n      (VBZ is)\n      (NP (NNP Gyarados) (NP (DT a) (NNP Pokémon) (NNS species))))\n    (. ?)))\n\n2\n(ROOT\n  (SQ\n    (VBZ does)\n    (NP (NNP Gyarados))\n    (VP\n      (VB appear)\n      (NP (JJ multiple) (NNS times))\n      (PP (IN in) (NP (NNP Pokémon)))\n      (PP\n        (IN under)\n        (NP\n          (NP (JJ various) (NNS trainers))\n          (PP\n            (JJ such)\n            (IN as)\n            (NP\n              (NP (NNP Misty))\n              (, ,)\n              (NP (NNP Lance))\n              (, ,)\n              (NP (NNP Crasher))))))\n      (VP (VBP Wake)))\n    (, ,)\n    (CC and)\n    (NP (NN Nurse) (NNP Joy))\n    (. ?)))\n\n3\n(ROOT\n  (SQ\n    (VBD did)\n    (NP (NN Author) (NNP Ash) (NNP Dekirk))\n    (VP\n      (VB write)\n      (SBAR\n        (IN that)\n        (S\n          (NP (NNP Gyarados) (CC and) (NNP Magikarp))\n          (VP\n            (VBD were)\n            (VP\n              (VBN inspired)\n              (PP\n                (IN by)\n                (NP\n                  (NP (DT the) (JJ Asiatic) (NN myth))\n                  (PP (IN of) (NP (DT the) (NNP Dragon) (NNP Gate))))))))))\n    (. ?)))\n\n4\n(ROOT\n  (SBARQ\n    (WHNP (WP who))\n    (SQ (VBZ is) (NP (NNP Gyarados)) (VP (VBN voiced) (PP (IN by))))\n    (. ?)))\n\n5\n(ROOT\n  (SBARQ\n    (PP (IN in) (NP (NNP Pokémon) (NNS Adventures)))\n    (, ,)\n    (SBAR\n      (WHNP (WDT what) (VBZ debuts))\n      (S\n        (PP (IN in) (NP (DT the) (NNP Red)))\n        (, ,)\n        (NP\n          (NNP Green)\n          (CC &)\n          (NNP Blue)\n          (NN chapter)\n          (PP (IN in) (NP (NNP Gyarados) (NNP Splashes)))\n          (PP (IN In) (NP (CD !?))))))))\n\n6\n(ROOT\n  (S\n    (NP\n      (NP (NN Gyarados))\n      (PRN\n        (-LRB- -LRB-)\n        (NP\n          (NP (CD ギャラドス))\n          (, ,)\n          (NP (NNP Gyaradosu))\n          (, ,)\n          (CC or)\n          (-RRB- -RRB-))))\n    (VP\n      (VBZ is)\n      (S\n        (NP\n          (NP (DT a) (NNP Pokémon) (NNS species))\n          (PP (IN in) (NP (NNP Nintendo) (CC and) (NNP Game))))\n        (NP (NP (NNP Freak) (POS 's)) (NNP Pokémon) (NN franchise))))\n    (. .)))\n\n"
    }
   ],
   "source": [
    "#Example Questions\n",
    "\n",
    "#Preprocessing: make first word lowercase if it is [\"is\", \"does\", \"was\", etc], but keep the question mark; test removing all other punctuation (\",\", \";\", etc)\n",
    "#Preprocessing NOTE: making every word lowercase messes up the classification done by the parser\n",
    "\n",
    "parser = CoreNLPParser(url='http://localhost:9000')\n",
    "\n",
    "query1 = \"is a red Gyarados found in Pokémon Gold?\"\n",
    "query2 = \"is Gyarados a Pokémon species?\"\n",
    "query3 = \"does Gyarados appear multiple times in Pokémon under various trainers such as Misty, Lance, Crasher Wake, and Nurse Joy?\"\n",
    "query4 = \"did Author Ash Dekirk write that Gyarados and Magikarp were inspired by the Asiatic myth of the Dragon Gate?\"\n",
    "query5 = \"who is Gyarados voiced by?\" #NOTE: For Sojeong\n",
    "query6 = \"in Pokémon Adventures, what debuts in the Red, Green & Blue chapter in Gyarados Splashes In!?\" #NOTE: For Sojeong\n",
    "test = \"Gyarados (ギャラドス, Gyaradosu,  or ) is a Pokémon species in Nintendo and Game Freak's Pokémon franchise.\" #NOTE: For Sojeong\n",
    "\n",
    "queryList = [query1, query2, query3, query4, query5, query6, test]\n",
    "listEntries = []\n",
    "entries = []\n",
    "for q in queryList:\n",
    "    result = parser.parse(q.split())\n",
    "    listResult = list(result)\n",
    "    entries.append(result)\n",
    "    listEntries.append(listResult)\n",
    "    #print(listResult)\n",
    "\n",
    "for i in range(len(listEntries)):\n",
    "    print(int(i))\n",
    "    print(listEntries[i][0]) #0 index to get to actual tree\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\nis a red Gyarados found in Pokémon Gold?\nQuestion Word: \nWas Declarative?: False\nNew Sentence: a red Gyarados is found in Pokémon Gold\n\n1\nis Gyarados a Pokémon species?\nQuestion Word: \nWas Declarative?: False\nNew Sentence: Gyarados is a Pokémon species\n\n2\ndoes Gyarados appear multiple times in Pokémon under various trainers such as Misty, Lance, Crasher Wake, and Nurse Joy?\nQuestion Word: \nWas Declarative?: False\nNew Sentence: Gyarados does appear multiple times in Pokémon under various trainers such as Misty , Lance , Crasher Wake , and Nurse Joy \n\n3\ndid Author Ash Dekirk write that Gyarados and Magikarp were inspired by the Asiatic myth of the Dragon Gate?\nQuestion Word: \nWas Declarative?: False\nNew Sentence: Author Ash Dekirk did write that Gyarados and Magikarp were inspired by the Asiatic myth of the Dragon Gate \n\n4\nwho is Gyarados voiced by?\nQuestion Word: who\nWas Declarative?: False\nNew Sentence: is Gyarados voiced by \n\n5\nin Pokémon Adventures, what debuts in the Red, Green & Blue chapter in Gyarados Splashes In!?\nQuestion Word: what\nWas Declarative?: False\nNew Sentence: in Pokémon Adventures , debuts in the Red , Green & Blue chapter in Gyarados Splashes In !\n\n6\nGyarados (ギャラドス, Gyaradosu,  or ) is a Pokémon species in Nintendo and Game Freak's Pokémon franchise.\nQuestion Word: \nWas Declarative?: True\nNew Sentence: Gyarados -LRB- ギャラドス , Gyaradosu , or -RRB- is a Pokémon species in Nintendo and Game Freak 's Pokémon franchise .\n\n"
    }
   ],
   "source": [
    "new_sentence_list = []\n",
    "for i in range(len(listEntries)):\n",
    "    print(int(i))\n",
    "    [question_word, was_declarative, new_sentence] = make_declarative(listEntries[i][0])\n",
    "    if new_sentence != \"\" and new_sentence[-1] == \"?\":\n",
    "        new_sentence = new_sentence[:-1] #Remove question mark\n",
    "    new_sentence_list.append(new_sentence)\n",
    "    print(queryList[i])\n",
    "    print(\"Question Word: \" + question_word)\n",
    "    print(\"Was Declarative?: \" + str(was_declarative))\n",
    "    print(\"New Sentence: \" + new_sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\na red Gyarados is found in Pokémon Gold\n(('found', 'VBN'), 'nsubjpass', ('Gyarados', 'NNPS'))\n(('Gyarados', 'NNPS'), 'det', ('a', 'DT'))\n(('Gyarados', 'NNPS'), 'amod', ('red', 'JJ'))\n(('found', 'VBN'), 'auxpass', ('is', 'VBZ'))\n(('found', 'VBN'), 'nmod', ('Gold', 'NNP'))\n(('Gold', 'NNP'), 'case', ('in', 'IN'))\n(('Gold', 'NNP'), 'compound', ('Pokémon', 'NNP'))\nIn Pokémon Gold, Silver, and Crystal, and their remakes, a red Gyarados is found in the Lake of Rage.\n(('Gold', 'NNP'), 'case', ('In', 'IN'))\n(('Gold', 'NNP'), 'compound', ('Pokémon', 'NNP'))\n(('Gold', 'NNP'), 'punct', (',', ','))\n(('Gold', 'NNP'), 'appos', ('Silver', 'NNP'))\n(('Gold', 'NNP'), 'punct', (',', ','))\n(('Gold', 'NNP'), 'cc', ('and', 'CC'))\n(('Gold', 'NNP'), 'conj', ('Crystal', 'NNP'))\n(('Gold', 'NNP'), 'punct', (',', ','))\n(('Gold', 'NNP'), 'cc', ('and', 'CC'))\n(('Gold', 'NNP'), 'conj', ('found', 'VBN'))\n(('found', 'VBN'), 'nsubjpass', ('remakes', 'NNS'))\n(('remakes', 'NNS'), 'nmod:poss', ('their', 'PRP$'))\n(('remakes', 'NNS'), 'punct', (',', ','))\n(('remakes', 'NNS'), 'appos', ('Gyarados', 'NNPS'))\n(('Gyarados', 'NNPS'), 'det', ('a', 'DT'))\n(('Gyarados', 'NNPS'), 'amod', ('red', 'JJ'))\n(('found', 'VBN'), 'auxpass', ('is', 'VBZ'))\n(('found', 'VBN'), 'nmod', ('Lake', 'NN'))\n(('Lake', 'NN'), 'case', ('in', 'IN'))\n(('Lake', 'NN'), 'det', ('the', 'DT'))\n(('Lake', 'NN'), 'nmod', ('Rage', 'NN'))\n(('Rage', 'NN'), 'case', ('of', 'IN'))\n(('Gold', 'NNP'), 'punct', ('.', '.'))\n\n1\nGyarados is a Pokémon species\n(('species', 'NNS'), 'nsubj', ('Gyarados', 'NNP'))\n(('species', 'NNS'), 'cop', ('is', 'VBZ'))\n(('species', 'NNS'), 'det', ('a', 'DT'))\n(('species', 'NNS'), 'compound', ('Pokémon', 'NNP'))\nGyarados (ギャラドス, Gyaradosu,  or ) is not a Pokémon species in Nintendo and Game Freak's Pokémon franchise.\n(('species', 'NNS'), 'nsubj', ('Gyarados', 'NN'))\n(('Gyarados', 'NN'), 'appos', ('ギャラドス', 'CD'))\n(('ギャラドス', 'CD'), 'punct', ('-LRB-', '-LRB-'))\n(('ギャラドス', 'CD'), 'punct', (',', ','))\n(('ギャラドス', 'CD'), 'appos', ('Gyaradosu', 'NNP'))\n(('ギャラドス', 'CD'), 'punct', (',', ','))\n(('ギャラドス', 'CD'), 'cc', ('or', 'CC'))\n(('ギャラドス', 'CD'), 'punct', ('-RRB-', '-RRB-'))\n(('species', 'NNS'), 'cop', ('is', 'VBZ'))\n(('species', 'NNS'), 'neg', ('not', 'RB'))\n(('species', 'NNS'), 'det', ('a', 'DT'))\n(('species', 'NNS'), 'compound', ('Pokémon', 'NNP'))\n(('species', 'NNS'), 'nmod', ('Nintendo', 'NNP'))\n(('Nintendo', 'NNP'), 'case', ('in', 'IN'))\n(('Nintendo', 'NNP'), 'cc', ('and', 'CC'))\n(('Nintendo', 'NNP'), 'conj', ('franchise', 'NN'))\n(('franchise', 'NN'), 'nmod:poss', ('Freak', 'NNP'))\n(('Freak', 'NNP'), 'compound', ('Game', 'NNP'))\n(('Freak', 'NNP'), 'case', (\"'s\", 'POS'))\n(('franchise', 'NN'), 'compound', ('Pokémon', 'NNP'))\n(('species', 'NNS'), 'punct', ('.', '.'))\n\n2\nGyarados does appear multiple times in Pokémon under various trainers such as Misty , Lance , Crasher Wake , and Nurse Joy \n(('appear', 'VB'), 'nsubj', ('Gyarados', 'NNP'))\n(('appear', 'VB'), 'aux', ('does', 'VBZ'))\n(('appear', 'VB'), 'dobj', ('times', 'NNS'))\n(('times', 'NNS'), 'amod', ('multiple', 'JJ'))\n(('times', 'NNS'), 'nmod', ('Pokémon', 'NNP'))\n(('Pokémon', 'NNP'), 'case', ('in', 'IN'))\n(('appear', 'VB'), 'nmod', ('trainers', 'NNS'))\n(('trainers', 'NNS'), 'case', ('under', 'IN'))\n(('trainers', 'NNS'), 'amod', ('various', 'JJ'))\n(('trainers', 'NNS'), 'nmod', ('Misty', 'NNP'))\n(('Misty', 'NNP'), 'case', ('such', 'JJ'))\n(('such', 'JJ'), 'mwe', ('as', 'IN'))\n(('Misty', 'NNP'), 'punct', (',', ','))\n(('Misty', 'NNP'), 'conj', ('Lance', 'NNP'))\n(('Misty', 'NNP'), 'punct', (',', ','))\n(('Misty', 'NNP'), 'conj', ('Wake', 'VBP'))\n(('Wake', 'VBP'), 'compound', ('Crasher', 'NNP'))\n(('Misty', 'NNP'), 'punct', (',', ','))\n(('Misty', 'NNP'), 'cc', ('and', 'CC'))\n(('Misty', 'NNP'), 'conj', ('Joy', 'NNP'))\n(('Joy', 'NNP'), 'compound', ('Nurse', 'NN'))\nGyarados does not appear multiple times in the anime under various trainers such as Misty, Lance, Crasher Wake, and Nurse Joy.\n(('appear', 'VB'), 'nsubj', ('Gyarados', 'NNP'))\n(('appear', 'VB'), 'aux', ('does', 'VBZ'))\n(('appear', 'VB'), 'neg', ('not', 'RB'))\n(('appear', 'VB'), 'dobj', ('times', 'NNS'))\n(('times', 'NNS'), 'amod', ('multiple', 'JJ'))\n(('times', 'NNS'), 'nmod', ('anime', 'NN'))\n(('anime', 'NN'), 'case', ('in', 'IN'))\n(('anime', 'NN'), 'det', ('the', 'DT'))\n(('times', 'NNS'), 'nmod', ('trainers', 'NNS'))\n(('trainers', 'NNS'), 'case', ('under', 'IN'))\n(('trainers', 'NNS'), 'amod', ('various', 'JJ'))\n(('trainers', 'NNS'), 'nmod', ('Misty', 'NNP'))\n(('Misty', 'NNP'), 'case', ('such', 'JJ'))\n(('such', 'JJ'), 'mwe', ('as', 'IN'))\n(('Misty', 'NNP'), 'punct', (',', ','))\n(('Misty', 'NNP'), 'conj', ('Lance', 'NNP'))\n(('Misty', 'NNP'), 'punct', (',', ','))\n(('Misty', 'NNP'), 'conj', ('Wake', 'VBP'))\n(('Wake', 'VBP'), 'compound', ('Crasher', 'NNP'))\n(('Misty', 'NNP'), 'punct', (',', ','))\n(('Misty', 'NNP'), 'cc', ('and', 'CC'))\n(('Misty', 'NNP'), 'conj', ('Joy', 'NNP'))\n(('Joy', 'NNP'), 'compound', ('Nurse', 'NN'))\n(('appear', 'VB'), 'punct', ('.', '.'))\n\n3\nAuthor Ash Dekirk did write that Gyarados and Magikarp were inspired by the Asiatic myth of the Dragon Gate \n(('write', 'VB'), 'nsubj', ('Dekirk', 'NNP'))\n(('Dekirk', 'NNP'), 'compound', ('Author', 'NN'))\n(('Dekirk', 'NNP'), 'compound', ('Ash', 'NNP'))\n(('write', 'VB'), 'aux', ('did', 'VBD'))\n(('write', 'VB'), 'ccomp', ('inspired', 'VBN'))\n(('inspired', 'VBN'), 'mark', ('that', 'DT'))\n(('inspired', 'VBN'), 'nsubjpass', ('Gyarados', 'NNPS'))\n(('Gyarados', 'NNPS'), 'cc', ('and', 'CC'))\n(('Gyarados', 'NNPS'), 'conj', ('Magikarp', 'NNP'))\n(('inspired', 'VBN'), 'auxpass', ('were', 'VBD'))\n(('inspired', 'VBN'), 'nmod', ('myth', 'NN'))\n(('myth', 'NN'), 'case', ('by', 'IN'))\n(('myth', 'NN'), 'det', ('the', 'DT'))\n(('myth', 'NN'), 'amod', ('Asiatic', 'JJ'))\n(('myth', 'NN'), 'nmod', ('Gate', 'NNP'))\n(('Gate', 'NNP'), 'case', ('of', 'IN'))\n(('Gate', 'NNP'), 'det', ('the', 'DT'))\n(('Gate', 'NNP'), 'compound', ('Dragon', 'NNP'))\nAuthor Ash Dekirk wrote that Gyarados and Magikarp were inspired by the Asiatic myth of the Dragon Gate.\n(('wrote', 'VBD'), 'nsubj', ('Dekirk', 'NNP'))\n(('Dekirk', 'NNP'), 'compound', ('Author', 'NN'))\n(('Dekirk', 'NNP'), 'compound', ('Ash', 'NNP'))\n(('wrote', 'VBD'), 'ccomp', ('inspired', 'VBN'))\n(('inspired', 'VBN'), 'mark', ('that', 'IN'))\n(('inspired', 'VBN'), 'nsubjpass', ('Gyarados', 'NNP'))\n(('Gyarados', 'NNP'), 'cc', ('and', 'CC'))\n(('Gyarados', 'NNP'), 'conj', ('Magikarp', 'NNP'))\n(('inspired', 'VBN'), 'auxpass', ('were', 'VBD'))\n(('inspired', 'VBN'), 'nmod', ('myth', 'NN'))\n(('myth', 'NN'), 'case', ('by', 'IN'))\n(('myth', 'NN'), 'det', ('the', 'DT'))\n(('myth', 'NN'), 'amod', ('Asiatic', 'JJ'))\n(('myth', 'NN'), 'nmod', ('Gate', 'NNP'))\n(('Gate', 'NNP'), 'case', ('of', 'IN'))\n(('Gate', 'NNP'), 'det', ('the', 'DT'))\n(('Gate', 'NNP'), 'compound', ('Dragon', 'NNP'))\n(('wrote', 'VBD'), 'punct', ('.', '.'))\n\n"
    }
   ],
   "source": [
    "dep_parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "corresponding_sentences = []\n",
    "'''\n",
    "query1 = \"is a red Gyarados found in Pokémon Gold?\"\n",
    "query2 = \"is Gyarados a Pokémon species?\"\n",
    "query3 = \"does Gyarados appear multiple times in Pokémon under various trainers such as Misty, Lance, Crasher Wake, and Nurse Joy?\"\n",
    "query4 = \"did Author Ash Dekirk write that Gyarados and Magikarp were inspired by the Asiatic myth of the Dragon Gate?\"\n",
    "'''\n",
    "s1 = \"In Pokémon Gold, Silver, and Crystal, and their remakes, a red Gyarados is found in the Lake of Rage.\" \n",
    "s2 = \"Gyarados (ギャラドス, Gyaradosu,  or ) is not a Pokémon species in Nintendo and Game Freak's Pokémon franchise.\"\n",
    "s3 = \"Gyarados does not appear multiple times in the anime under various trainers such as Misty, Lance, Crasher Wake, and Nurse Joy.\"\n",
    "s4 = \"Author Ash Dekirk wrote that Gyarados and Magikarp were inspired by the Asiatic myth of the Dragon Gate.\"\n",
    "corresponding_sentences.append(s1)\n",
    "corresponding_sentences.append(s2) #NOTE: This was negated from original text\n",
    "corresponding_sentences.append(s3) #NOTE: This was negated from original text\n",
    "corresponding_sentences.append(s4)\n",
    "\n",
    "dep_new = []\n",
    "dep_sentences = []\n",
    "\n",
    "for i in range(len(new_sentence_list)):\n",
    "    if i == 4: #Only first 4 are yes/no questions\n",
    "        break\n",
    "    print(i)\n",
    "    \n",
    "    #Rearranged Questions then Corresponding Sentences\n",
    "    listed = [new_sentence_list[i], corresponding_sentences[i]]\n",
    "    for k in range(len(listed)):\n",
    "        s = listed[k]\n",
    "        parses = dep_parser.parse(s.split())\n",
    "        print(s)\n",
    "        result = [[(governor, dep, dependent) for governor, dep, dependent in p.triples()] for p in parses]\n",
    "\n",
    "        if k == 0: dep_new.append(result)\n",
    "        else: dep_sentences.append(result)\n",
    "\n",
    "        for i in range(len(result[0])):\n",
    "            print(result[0][i])\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "YES\nNO: reason 5\nNO: reason 5\nYES\n"
    }
   ],
   "source": [
    "#Use dependency parses to compare restructured question and corresponding statement to answer yes or no\n",
    "#NOTE: dep_new and dep_sentences should be the same length\n",
    "for i in range(len(dep_new)):\n",
    "    dep_n = dep_new[i]\n",
    "    dep_s = dep_sentences[i]\n",
    "\n",
    "    #Save governors and corresponding deps for comparison\n",
    "    n_governors = dict() #NOTE: dependent are tuples while governors(keys) and dep are a string\n",
    "    s_governors = dict()\n",
    "\n",
    "    dependencies = [dep_n[0], dep_s[0]]\n",
    "    governors = [n_governors, s_governors]\n",
    "\n",
    "    for k in range(len(dependencies)):\n",
    "        dpnd = dependencies[k]\n",
    "        govs = governors[k]\n",
    "        #print(dpnd)\n",
    "\n",
    "        for item in dpnd:\n",
    "            g_word = item[0][0]\n",
    "            #print(g_word)\n",
    "            g_pos = item[0][1]\n",
    "            #print(g_pos)\n",
    "            dep = item[1]\n",
    "            #print(dep)\n",
    "            dependent = item[2]\n",
    "            #print(dependent)\n",
    "\n",
    "            #If the governor is a verb, store its base form as the key\n",
    "            if g_pos.startswith(\"V\"): \n",
    "                g_word = lemmatizer.lemmatize(g_word, pos=\"v\")\n",
    "\n",
    "            #Add new word to dictionary if not there\n",
    "            if g_word not in govs:\n",
    "                govs[g_word] = dict()\n",
    "\n",
    "                #Check again if pos is a verb to add new field in dictionary\n",
    "                #for its part of speech before base form form dictionary\n",
    "                if g_pos.startswith(\"V\"): \n",
    "                    govs[g_word][\"lem\"] = g_pos\n",
    "\n",
    "            if dep in [\"cop\", \"aux\", \"auxpass\", \"neg\"]: #Special case to handle verb conjugations\n",
    "                if \"verb\" not in govs[g_word]:\n",
    "                    govs[g_word][\"verb\"] = set()\n",
    "                govs[g_word][\"verb\"].add(dependent)\n",
    "            govs[g_word][dep] = dependent\n",
    "\n",
    "    #Check for existence of each governor in sentence (with corresponding dependents when necessary)\n",
    "    bool_yes = True\n",
    "    #print(n_governors.keys())\n",
    "    for key in n_governors.keys():\n",
    "\n",
    "        #print(key)\n",
    "        #If head is not in other parse, then it is false\n",
    "        if key not in s_governors.keys():\n",
    "            print(\"NO: reason 1\")\n",
    "            bool_yes = False\n",
    "            break\n",
    "        \n",
    "        #If subject and direct object are not present, then it is false\n",
    "        if (\"nsubj\" in n_governors[key]):\n",
    "            if (\"nsubj\" not in s_governors[key]):\n",
    "                print(\"NO: reason 2\")\n",
    "                bool_yes = False\n",
    "                break\n",
    "        if (\"nsubjpass\" in n_governors[key]):\n",
    "            if (\"nsubjpass\" not in s_governors[key]):\n",
    "                print(\"NO: reason 3\")\n",
    "                bool_yes = False\n",
    "                break\n",
    "        if (\"dobj\" in n_governors[key]):\n",
    "            if (\"dobj\" not in s_governors[key]):\n",
    "                print(\"NO: reason 4\")\n",
    "                bool_yes = False\n",
    "                break\n",
    "\n",
    "        #If key is a verb in its lemmatized form or has copula\n",
    "        #Check to see if one is negated and the other is not\n",
    "        #FIXME: Can make more complex check of verb tenses as well\n",
    "        if \"lem\" in n_governors[key] or \"verb\" in n_governors[key]: #store up verb information to deal with\n",
    "            n_neg = \"neg\" in n_governors[key]\n",
    "            s_neg = \"neg\" in s_governors[key]\n",
    "\n",
    "            if n_neg != s_neg:\n",
    "                print(\"NO: reason 5\")\n",
    "                bool_yes = False\n",
    "                break\n",
    "    \n",
    "    if bool_yes:\n",
    "        print(\"YES\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'go_after', 'Canis_familiaris', 'frank', 'track', 'frump', 'hound', 'give_chase', 'wienerwurst', 'pawl', 'hot_dog', 'click', 'chase', 'blackguard', 'dog-iron', 'tag', 'andiron', 'hotdog', 'wiener', 'detent', 'frankfurter', 'dog', 'trail', 'bounder', 'domestic_dog', 'chase_after', 'weenie', 'firedog', 'heel', 'tail', 'cad'}\nSynset name :   dog.n.01\n\nSynset abstract term :   [Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n\nSynset specific term :   [Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), Synset('great_pyrenees.n.01'), Synset('griffon.n.02'), Synset('hunting_dog.n.01'), Synset('lapdog.n.01'), Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'), Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), Synset('pug.n.01'), Synset('puppy.n.01'), Synset('spitz.n.01'), Synset('toy_dog.n.01'), Synset('working_dog.n.01')]\n\nHyper:  {'canine', 'canid'}\n\nHypo:  {'basenji', 'mutt', 'spitz', 'Leonberg', 'Newfoundland', 'pug', 'pug-dog', 'dalmatian', 'toy', 'corgi', 'griffon', 'barker', 'mongrel', 'pooch', 'cur', 'doggy', 'poodle', 'doggie', 'puppy', 'lapdog', 'bow-wow'}\n"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "#https://www.geeksforgeeks.org/nlp-synsets-for-a-word-in-wordnet/\n",
    "#https://www.geeksforgeeks.org/get-synonymsantonyms-nltk-wordnet-python/\n",
    "\n",
    "#NOTE: With current system, will only be able to check for one word replacements\n",
    "# Therefore multi-word replacements may still be missed\n",
    "\n",
    "syns = wordnet.synsets('dog')\n",
    "\n",
    "first = syns[0]\n",
    "\n",
    "synonyms = set()\n",
    "for syn in syns: \n",
    "    for l in syn.lemmas(): \n",
    "        synonyms.add(l.name()) \n",
    "print(synonyms)\n",
    "\n",
    "print (\"Synset name :  \", first.name())\n",
    "\n",
    "hyper = first.hypernyms()\n",
    "print (\"\\nSynset abstract term :  \", hyper) \n",
    "  \n",
    "hyper_words = set()\n",
    "for m in hyper:\n",
    "    #hyper_words.add(m.name())\n",
    "    for word in m.lemmas():\n",
    "        phrase = word.name().replace(\"_\", \" \") #Eliminating underscores to show one word vs 2 word statements\n",
    "        if len(phrase.split()) == 1: #Identifying single word replacements\n",
    "            hyper_words.add(phrase)\n",
    "\n",
    "hypo = first.hyponyms()\n",
    "print (\"\\nSynset specific term :  \",  \n",
    "       hypo) \n",
    "  \n",
    "hypo_words = set()\n",
    "for k in hypo:\n",
    "    #hypo_words.add(k.name())\n",
    "    for word in k.lemmas():\n",
    "        phrase = word.name().replace(\"_\", \" \") #Eliminating underscores to show one word vs 2 word statements\n",
    "        if len(phrase.split()) == 1: #Identifying single word replacements\n",
    "            hypo_words.add(phrase)\n",
    "  \n",
    "print (\"\\nHyper: \", hyper_words)\n",
    "print (\"\\nHypo: \", hypo_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bit58b581aa823b48d68caa55b91f5030c4",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}